{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python is running inside a virtual environment c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if sys.prefix != sys.base_prefix:\n",
    "    print(f\"Python is running inside a virtual environment {sys.prefix}.\")\n",
    "else:\n",
    "    print(f\"Python is running outside a virtual environment {sys.base_prefix}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cuml"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [47 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please avoid running ``setup.py`` directly.\n",
      "              Instead, use pypa/build, pypa/installer or other\n",
      "              standards-based tools.\n",
      "      \n",
      "              See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self.initialize_options()\n",
      "      installing to build\\bdist.win-amd64\\wheel\n",
      "      running install\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\peeyu\\AppData\\Local\\Temp\\pip-install-x_sqs377\\cuml_6455c79d689e44988fbbd8e276020efe\\setup.py\", line 18, in <module>\n",
      "          setup(name=pkg,\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\__init__.py\", line 103, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 185, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 201, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 969, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\wheel\\bdist_wheel.py\", line 404, in run\n",
      "          self.run_command(\"install\")\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 318, in run_command\n",
      "          self.distribution.run_command(command)\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\dist.py\", line 963, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"c:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\.venv\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 988, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\peeyu\\AppData\\Local\\Temp\\pip-install-x_sqs377\\cuml_6455c79d689e44988fbbd8e276020efe\\setup.py\", line 15, in run\n",
      "          raise Exception(long_description)\n",
      "      Exception: Please install cuml via the rapidsai conda channel. See https://rapids.ai/start.html for instructions.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for cuml\n",
      "ERROR: Could not build wheels for cuml, which is required to install pyproject.toml-based projects\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached cuml-0.6.1.post1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: cuml\n",
      "  Building wheel for cuml (setup.py): started\n",
      "  Building wheel for cuml (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for cuml\n",
      "Failed to build cuml\n"
     ]
    }
   ],
   "source": [
    "!pip install cuml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\UMD\\Sem 1\\MSML602 Principles in Data Science\\Assignment 4\\assignment4.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/UMD/Sem%201/MSML602%20Principles%20in%20Data%20Science/Assignment%204/assignment4.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcuml\u001b[39;00m \u001b[39mimport\u001b[39;00m TruncatedSVD\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "from cuml import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gzip\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'C:\\\\UMD\\\\Sem 1\\\\MSML602 Principles in Data Science\\\\Assignment 4'\n",
    "gzip_file_name = f'{base_path}\\\\finefoods.txt.gz'\n",
    "file_name = f'{base_path}\\\\finefoods.txt'\n",
    "if not os.path.exists(gzip_file_name):\n",
    "    os.system(\"wget https://snap.stanford.edu/data/finefoods.txt.gz\")\n",
    "\n",
    "binary_data = gzip.open(gzip_file_name, 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product/productId   review/userId               review/profileName  \\\n",
      "0             B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
      "1             B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
      "2             B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
      "3             B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
      "4             B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
      "...                  ...             ...                              ...   \n",
      "568449        B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
      "568450        B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
      "568451        B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
      "568452        B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
      "568453        B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
      "\n",
      "       review/helpfulness review/score review/time  \\\n",
      "0                     1/1          5.0  1303862400   \n",
      "1                     0/0          1.0  1346976000   \n",
      "2                     1/1          4.0  1219017600   \n",
      "3                     3/3          2.0  1307923200   \n",
      "4                     0/0          5.0  1350777600   \n",
      "...                   ...          ...         ...   \n",
      "568449                0/0          5.0  1299628800   \n",
      "568450                0/0          2.0  1331251200   \n",
      "568451                2/2          5.0  1329782400   \n",
      "568452                1/1          5.0  1331596800   \n",
      "568453                0/0          5.0  1338422400   \n",
      "\n",
      "                            review/summary  \\\n",
      "0                    Good Quality Dog Food   \n",
      "1                        Not as Advertised   \n",
      "2                    \"Delight\" says it all   \n",
      "3                           Cough Medicine   \n",
      "4                              Great taffy   \n",
      "...                                    ...   \n",
      "568449                 Will not do without   \n",
      "568450                        disappointed   \n",
      "568451            Perfect for our maltipoo   \n",
      "568452  Favorite Training and reward treat   \n",
      "568453                         Great Honey   \n",
      "\n",
      "                                              review/text  \n",
      "0       I have bought several of the Vitality canned d...  \n",
      "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
      "2       This is a confection that has been around a fe...  \n",
      "3       If you are looking for the secret ingredient i...  \n",
      "4       Great taffy at a great price.  There was a wid...  \n",
      "...                                                   ...  \n",
      "568449  Great for sesame chicken..this is a good if no...  \n",
      "568450  I'm disappointed with the flavor. The chocolat...  \n",
      "568451  These stars are small, so you can give 10-15 o...  \n",
      "568452  These are the BEST treats for training and rew...  \n",
      "568453  I am very satisfied ,product is as advertised,...  \n",
      "\n",
      "[568454 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(gzip_file_name, 'r') as file: lines = file.readlines()\n",
    "\n",
    "# Initialize an empty list to store dictionaries\n",
    "data = []\n",
    "\n",
    "# Initialize a dictionary to store key-value pairs for each paragraph\n",
    "current_paragraph = {}\n",
    "last_key = ''\n",
    "\n",
    "# Loop through each line\n",
    "for line in lines:\n",
    "    # If the line is not empty, split it into key and value\n",
    "    line = line.decode('Windows-1252').strip()\n",
    "    if line:\n",
    "        line_data = line.split(\":\", 1)\n",
    "        assert len(line_data) <= 2, f\"More than 2 elements, {line_data}\"\n",
    "        if len(line_data) == 1:\n",
    "            current_paragraph[last_key] += line_data[0]\n",
    "        else:\n",
    "            key, value = line_data\n",
    "            current_paragraph[key] = value.strip()\n",
    "            last_key = key\n",
    "    else:\n",
    "        # If the line is empty, it indicates the end of a paragraph\n",
    "        # Append the dictionary to the data list and reset for the next paragraph\n",
    "        data.append(current_paragraph)\n",
    "        current_paragraph = {}\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review/score'] = df['review/score'].astype(float).astype(int)\n",
    "df['review/time'] = pd.to_datetime(df['review/time'].astype(int), unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(df['review/text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I split `X_tfidf` into training and test data with an 80%, 20% split (assume `X_train` and `X_test` respectively), the training data is of 407. GiB and an array with shape (454763, 120252) and each data type is float64. Generally, gaussian requires matrix and passing this enormous amount of data is not possible. \n",
    "\n",
    "So, one needs to do PCA or SVD and then take the most important dataset to do GaussianNB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 120252)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568454, 1000) 0.5721161653797121\n"
     ]
    }
   ],
   "source": [
    "svd = TruncatedSVD(n_components=1000)\n",
    "X_svd = svd.fit_transform(X_tfidf)\n",
    "explained_variance = np.sum(svd.explained_variance_ratio_)\n",
    "print(X_svd.shape, explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_svd, df['review/score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.48\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.19      0.57      0.28     10326\n",
      "           2       0.15      0.14      0.14      5855\n",
      "           3       0.19      0.22      0.21      8485\n",
      "           4       0.26      0.21      0.23     16123\n",
      "           5       0.77      0.58      0.66     72902\n",
      "\n",
      "    accuracy                           0.48    113691\n",
      "   macro avg       0.31      0.34      0.31    113691\n",
      "weighted avg       0.57      0.48      0.51    113691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/UMD/Sem 1/MSML602 Principles in Data Science/.venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "svd2 = TruncatedSVD(n_components=2000)\n",
    "X_svd2 = svd2.fit_transform(X_tfidf)\n",
    "explained_variance2 = np.sum(svd2.explained_variance_ratio_)\n",
    "print(X_svd2.shape, explained_variance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_svd2, df['review/score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Gaussian Naive Bayes\n",
    "classifier2 = GaussianNB()\n",
    "classifier2.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "predictions2 = classifier2.predict(X_test2)\n",
    "\n",
    "# Evaluate the classifier\n",
    "accuracy2 = accuracy_score(y_test2, predictions2)\n",
    "print(f'Accuracy: {accuracy2:.2f}')\n",
    "\n",
    "# Display classification report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test2, predictions2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
